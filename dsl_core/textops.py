"""Aggregated text/surface helpers used by the DSL renderers."""

from __future__ import annotations

import random
import re
from typing import Optional

from .utils import (
    enc_base64,
    enc_url,
    enc_html_entity,
    enc_hex,
    enc_rot13,
    enc_fullwidth,
    insert_zwsp,
    payload_variants,
)

try:  # pragma: no cover - optional dependency
    from opencc import OpenCC  # type: ignore
except Exception:  # pragma: no cover - fallback when opencc is absent
    OpenCC = None  # type: ignore

__all__ = [
    # Encoders (re-exported from utils)
    "enc_base64",
    "enc_url",
    "enc_html_entity",
    "enc_hex",
    "enc_rot13",
    "enc_fullwidth",
    "insert_zwsp",
    "payload_variants",
    # Noise helpers
    "CODE_BLOCK_RE",
    "apply_cn_eco_noise",
    # Surface/region helpers
    "apply_cn_region",
    "sinicize_surface",
    # Alias helpers
    "ALIAS_MAP",
    "CN_ALIAS_MAP",
    "randomize_field_aliases",
]

# ---------------------------------------------------------------------------
# CN surface noise
# ---------------------------------------------------------------------------

_EMOS = ["ğŸ˜Š", "ğŸ˜‚", "ğŸ˜…", "ğŸ˜‰", "ğŸ¤”", "ğŸ˜", "ğŸ˜‘", "ğŸ™‚", "ğŸ™ƒ", "ğŸ¤«", "ğŸ˜´", "ğŸ˜®"]
_FILLERS = ["å‘€", "æ¬¸", "å•Š", "å“Ÿ", "å’¦", "å“", "è¯¶å‘€", "å“å‘€", "å‘", "å‘ƒ", "å¯¹å§", "å‘—", "emmm", "emm", "233", "å“ˆå“ˆå“ˆ"]
_PUNCT_SWAP = {"ï¼Œ": "ã€‚", "ã€‚": ",", "ï¼š": ":", "ï¼›": ";", "ï¼": "!", "ï¼Ÿ": "?", "â€”": "-", "ï½": "~"}
CODE_BLOCK_RE = re.compile(r"```(?P<lang>[A-Za-z0-9_+-]+)?\s*\n([\s\S]*?)```", re.M | re.S)


def _apply_cn_eco_free(seg: str, rng: random.Random, rate: float) -> str:
    s = seg
    if not s.strip():
        return s
    if rng.random() < rate:
        s = "".join(_PUNCT_SWAP.get(ch, ch) if rng.random() < 0.15 else ch for ch in s)
    if rng.random() < rate * 0.6:
        if rng.random() < 0.5:
            s = rng.choice(_FILLERS) + "ï¼Œ" + s
        else:
            s = s + rng.choice(["å‘€", "å•¦"]) + rng.choice(_EMOS)
    if rng.random() < rate * 0.4:
        if "ç»“æœ" in s and rng.random() < 0.5:
            s = s.replace("ç»“æœ", "result")
        if "å·¥å…·" in s and rng.random() < 0.3:
            s = s.replace("å·¥å…·", "tool")
    if rng.random() < rate * 0.3:
        if "æ³¨æ„" in s:
            s = s.replace("æ³¨æ„", "æ³¨æ„å™¢")
        if "è·¯å¾„" in s and rng.random() < 0.5:
            s = s.replace("è·¯å¾„", "é€”ç»")
    return s


def apply_cn_eco_noise(text: str, rng: random.Random, rate: float = 0.18) -> str:
    """Inject light code-switch and colloquial noise into natural-language spans."""
    out: list[str] = []
    last = 0
    t = text or ""
    for match in CODE_BLOCK_RE.finditer(t):
        if match.start() > last:
            out.append(_apply_cn_eco_free(t[last:match.start()], rng, rate))
        out.append(match.group(0))
        last = match.end()
    if last < len(t):
        out.append(_apply_cn_eco_free(t[last:], rng, rate))
    return "".join(out)


# ---------------------------------------------------------------------------
# Regional normalisation & directive sinicization
# ---------------------------------------------------------------------------

_cn2tw = _tw2cn = None
if OpenCC is not None:  # pragma: no cover - exercised when opencc is installed
    try:
        _cn2tw = OpenCC("s2twp")
        _tw2cn = OpenCC("tw2s")
    except Exception:  # pragma: no cover - guard errant configs
        _cn2tw = _tw2cn = None


def apply_cn_region(text: str, region: str) -> str:
    """Convert Simplified/Traditional surface forms depending on region."""
    result = text
    try:
        if region == "tw" and _cn2tw:
            result = _cn2tw.convert(text)
        if region == "cn_mainland" and _tw2cn:
            result = _tw2cn.convert(text)
    except Exception:
        result = text
    return result


def sinicize_surface(text: str) -> str:
    """Replace key English directives with CN aliases, skipping fenced code."""

    replacements = {
        "only output": "ä»…è¾“å‡º",
        "final answer": "æœ€ç»ˆç­”æ¡ˆ",
        "result slot": "ç»“æœæ§½ä½",
        "ignore above": "å¿½ç•¥ä»¥ä¸Šå†…å®¹",
        "override": "ä»¥æ­¤æ®µä¸ºå‡†",
        "append": "è¿½åŠ ",
        "tool": "å·¥å…·",
        "role": "è§’è‰²",
        "path": "è·¯å¾„",
        "upstream": "ä¸Šæ¸¸",
    }

    def _transform(segment: str) -> str:
        out = segment
        for key, value in replacements.items():
            out = re.sub(rf"\b{re.escape(key)}\b", value, out, flags=re.I)
        return out

    parts: list[str] = []
    last = 0
    src = text or ""
    for match in CODE_BLOCK_RE.finditer(src):
        if match.start() > last:
            parts.append(_transform(src[last:match.start()]))
        parts.append(match.group(0))
        last = match.end()
    if last < len(src):
        parts.append(_transform(src[last:]))
    return "".join(parts)


# ---------------------------------------------------------------------------
# Field alias randomisation
# ---------------------------------------------------------------------------

ALIAS_MAP = {
    r"\b(?:note|remark|comment)\b": ["å¤‡æ³¨", "è¯´æ˜", "æ³¨è®°"],
    r"\b(?:result|answer|verdict|final)\b": ["ç»“æœ", "ç­”æ¡ˆ", "ç»“è®º"],
    r"\brole\b": ["è§’è‰²", "é€šé“è§’è‰²"],
    r"\b(?:path|file|location)\b": ["è·¯å¾„", "æ–‡ä»¶è·¯å¾„"],
    r"\b(?:upstream|source)\b": ["ä¸Šæ¸¸", "æ¥æº"],
    r"\b(?:append|suffix|footer)\b": ["è¿½åŠ ", "å°¾æ³¨", "é™„æ³¨"],
    r"\b(?:tool|function_call|args|arguments)\b": ["å·¥å…·", "å‡½æ•°è°ƒç”¨", "å‚æ•°"],
    r"\bdirectives?\b": ["æŒ‡ä»¤", "æç¤º"],
    r"\btitle\b": ["æ ‡é¢˜", "é¢˜å"],
    r"\b(?:summary|abstract)\b": ["æ‘˜è¦", "æ¦‚è§ˆ"],
    r"\btags?\b": ["æ ‡ç­¾", "å…³é”®è¯"],
    r"\bstatus\b": ["çŠ¶æ€", "è¿›åº¦"],
    r"\b(?:category|type)\b": ["ç±»åˆ«", "ç±»å‹"],
    r"\b(?:author|owner)\b": ["ä½œè€…", "è´Ÿè´£äºº"],
    r"\b(?:date|time|datetime|timestamp)\b": ["æ—¥æœŸ", "æ—¶é—´"],
}

CN_ALIAS_MAP = {
    "è¯„æµ‹é€šé“": ["è¯„æµ‹é€šé“", "è¯„åˆ†é€šé“", "è¯„å®¡é€šé“", "æ‰“åˆ†é€šé“", "å®¡æŸ¥é€šé“"],
    "å¾—åˆ†": ["å¾—åˆ†", "è¯„åˆ†", "åˆ†å€¼", "è¯„ä¼°å€¼", "è¯„åˆ†å€¼"],
    "è®°å¿†å†™å…¥": ["è®°å¿†å†™å…¥", "å†™å…¥è®°å¿†", "å­˜å‚¨è®°å¿†", "æŒä¹…åŒ–è®°å¿†", "å­˜æ¡£"],
    "å›åˆçŠ¶æ€": ["å›åˆçŠ¶æ€", "è½®æ¬¡çŠ¶æ€", "ä¼šè¯è½®æ¬¡", "é˜¶æ®µçŠ¶æ€", "çŠ¶æ€è¿ç§»"],
    "ç»“æœæ§½": ["ç»“æœæ§½", "ç»“æœå­—æ®µ", "è¾“å‡ºæ§½", "ç›®æ ‡æ§½", "ç»“æœä½"],
}


def randomize_field_aliases(text: str, p_cn: float = 0.7, rng: Optional[random.Random] = None) -> str:
    """
    Probabilistically replace common field names with Chinese aliases.
    Intended for JSON/YAML/front-matter style blobs; Markdown tables are
    not modified explicitly.
    """

    _rng = rng or random
    t = text

    for pattern, cn_list in ALIAS_MAP.items():
        replacement = _rng.choice(cn_list)
        t = re.sub(
            rf'(")({pattern})(")\s*:',
            lambda m: m.group(1) + (replacement if _rng.random() < p_cn else m.group(2)) + m.group(3) + ":",
            t,
            flags=re.I,
        )
        t = re.sub(
            rf"(?m)^({pattern})\s*:",
            lambda m: (replacement if _rng.random() < p_cn else m.group(1)) + ":",
            t,
            flags=re.I,
        )

    def _rand_cn(word: str) -> str:
        alts = CN_ALIAS_MAP.get(word)
        if not alts:
            return word
        return _rng.choice(alts) if _rng.random() < float(p_cn) else word

    t = re.sub(
        r"(?m)^(\s*)(è¯„æµ‹é€šé“|å¾—åˆ†|è®°å¿†å†™å…¥|å›åˆçŠ¶æ€|ç»“æœæ§½)(\s*:\s*)",
        lambda m: f"{m.group(1)}{_rand_cn(m.group(2))}{m.group(3)}",
        t,
    )
    return t
